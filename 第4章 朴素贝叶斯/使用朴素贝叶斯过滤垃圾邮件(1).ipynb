{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用朴素贝叶斯过滤垃圾邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**说明:**\n",
    "\n",
    "将 `email` 文件夹放在当前目录下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义创建列表函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "createVocabList()函数会创建一个包含在所有文档中出现的不重复词的列表\n",
    "\n",
    "\"\"\"\n",
    "def createVocabList(dataSet):\n",
    "    #创建一个空集\n",
    "    vocabSet = set([])  \n",
    "    for document in dataSet:\n",
    "        #再创建一个空集后，将每篇文档返回的新词集合添加到该集合中，再求两个集合的并集\n",
    "        vocabSet = vocabSet | set(document) \n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义词集模型函数（set-of-words）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "该函数输入参数为词汇表及某个文档，输出的是文档向量，向量的每一个元素为1或者0，分别\n",
    "表示词汇表中的单词在输入文档中是否出现\n",
    "\n",
    "\"\"\"\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    #函数首先创建一个和词汇表等长的向量，并将其元素都设置为0\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    #接着，遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1。\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义词袋模型函数（bag-of-words）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef bagOfWords2VecMN(vocabList, inputSet):\\n    returnVec = [0]*len(vocabList)\\n    for word in inputSet:\\n        if word in vocabList:\\n            returnVec[vocabList.index(word)] += 1\\n    return returnVec\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def bagOfWords2VecMN(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "    return returnVec\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义朴素贝叶斯分类器训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:朴素贝叶斯分类器训练函数\n",
    "trainMatrix--训练文档矩阵，即setOfWords2Vec返回的returnVec构成的矩阵；trainCategory--训练类别标签向量\n",
    "p1Vect--标记为1的类条件概率数组；p0Vect--标记为0的类条件概率数组；pAbusive是标记为1类的先验概率\n",
    "\"\"\"\n",
    "def trainNB(trainMatrix, trainCategory):\n",
    "    #计算训练的文档数目\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    #计算每篇文档的词条数\n",
    "    numWords = len(trainMatrix[0])\n",
    "    #标记为1类的先验概率\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
    "    \"\"\"\n",
    "    创建numpy数组初始化为1，拉普拉斯平滑。\n",
    "    创建numpy.zeros数组,词条出现数初始化为0。分母初始化为2\n",
    "    \n",
    "    \"\"\"\n",
    "    p0Num = np.ones(numWords); p1Num = np.ones(numWords)      \n",
    "    p0Denom = 2.0; p1Denom = 2.0  \n",
    "    #计算类条件概率\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Denom += 1\n",
    "           # p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += 1\n",
    "            #p0Denom += sum(trainMatrix[i])\n",
    "    #由于大部分因子都非常小，防止数值下溢得不到正确答案。于是加log计算，可以使得答案不会过小。\n",
    "    p1Vect = np.log(p1Num/p1Denom)          #change to np.log()\n",
    "    p0Vect = np.log(p0Num/p0Denom)          #change to np.log()\n",
    "    return p0Vect, p1Vect, pAbusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义朴素贝叶斯分类器预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)    #element-wise mult\n",
    "    p0 = sum(vec2Classify * p0Vec) + np.log(1.0 - pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\"\"\"\n",
    "\n",
    "#函数说明:朴素贝叶斯分类器分类函数\n",
    "#vec2Classify--待分类的词条数组; p1Vec--标记为类1的类条件概率数组; p0Vec--标记为类0的类条件概率数组; pClass1--标记为1类的先验概率\n",
    "\"\"\"\n",
    "博客\n",
    "https://blog.csdn.net/qq_27009517/article/details/80044431\n",
    "https://blog.csdn.net/lming_08/article/details/37542331\n",
    "\"\"\"\n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    \"\"\"\n",
    "    1.计算待分类词条数组为1类的概率\n",
    "    \"\"\"\n",
    "    #寻找vec2Classify测试数组中，元素为0时对应的索引值\n",
    "    index = np.where(vec2Classify==0)\n",
    "    #遍历元素为0时的索引值，并从p1Vec--1类的条件概率数组中取出对应索引的数值，并存储成列表的形式（p1Vec0=[]）\n",
    "    p1Vec0=[]\n",
    "    for i in index:\n",
    "        for m in i:\n",
    "            p1Vec0.append(p1Vec[m])\n",
    "    #所有1-P(vec2Classify=0|1)组成的列表\n",
    "        x0=np.ones(len(p1Vec0))-p1Vec0\n",
    "    #寻找vec2Classify测试数组中，元素为1时对应的索引值\n",
    "    index1= np.where(vec2Classify==1)\n",
    "    #遍历元素为1时的索引值，并从p1Vec--1类的条件概率数组中取出对应索引的数值，并存储成列表的形式（p1Vec1=[]）\n",
    "    p1Vec1=[]\n",
    "    for i in index1:\n",
    "        for m in i:\n",
    "            p1Vec1.append(p1Vec[m])\n",
    "    #所有P(vec2Classify=0|1)组成的列表\n",
    "    x1=p1Vec1      \n",
    "    ##对应元素相乘。logA * B = logA + logB，所以这里加上log(pClass1)\n",
    "    p1 = sum(x0)+sum(x1) +  np.log(pClass1)        \n",
    "    \"\"\"\n",
    "    2.计算待分类词条数组为0类的概率\n",
    "    \"\"\"\n",
    "    \n",
    "    #寻找vec2Classify测试数组中，元素为0时对应的索引值\n",
    "    index2 = np.where(vec2Classify==0)\n",
    "    #遍历元素为0时的索引值，并从p0Vec--0类的条件概率数组中取出对应索引的数值，并存储成列表的形式（p0Vec0=[]）\n",
    "    p0Vec0=[]\n",
    "    for i in index2:\n",
    "        for m in i:\n",
    "            p0Vec0.append(p0Vec[m])\n",
    "    #所有1-P(vec2Classify=0|0)组成的列表\n",
    "    w0=np.ones(len(p0Vec0))-p0Vec0\n",
    "    #寻找vec2Classify测试数组中，元素为1时对应的索引值\n",
    "    index3= np.where(vec2Classify==1)\n",
    "    #遍历元素为1时的索引值，并从p0Vec--0类的条件概率数组中取出对应索引的数值，并存储成列表的形式（p0Vec1=[]）\n",
    "    p0Vec1=[]\n",
    "    for i in index3:\n",
    "        for m in i:\n",
    "            p0Vec1.append(p0Vec[m])\n",
    "    #所有1-P(vec2Classify=0|0)组成的列表\n",
    "    w1=p0Vec1\n",
    "    ##对应元素相乘。logA * B = logA + logB，所以这里加上log(pClass1)\n",
    "    p0 = sum(w0)+sum(w1) +  np.log(1.0 - pClass1)\n",
    "    \n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用朴素贝叶斯过滤垃圾邮件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "书本中4.6.1节 准备数据，切分文本部分写的很清晰。\n",
    "\"\"\"\n",
    "#将一个大字符串解析为字符列表。input is big string, #output is word list\n",
    "def textParse(bigString):    \n",
    "    import re\n",
    "    listOfTokens = re.split(r'\\W+', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamTest():\n",
    "    docList = []; classList = []; fullText = []\n",
    "    #遍历25个txt文件\n",
    "    for i in range(1, 26):\n",
    "        #读取每个垃圾邮件，大字符串转换成字符列表。\n",
    "        wordList = textParse(open('email/spam/%d.txt' % i, encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        #标记垃圾邮件，1表示垃圾邮件\n",
    "        classList.append(1)\n",
    "        #读取每个非垃圾邮件，字符串转换为字符列表\n",
    "        wordList = textParse(open('email/ham/%d.txt' % i, encoding=\"ISO-8859-1\").read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        #标记每个非垃圾邮件，0表示非垃圾邮件\n",
    "        classList.append(0)\n",
    "    #创建词汇表，不重复\n",
    "    vocabList = createVocabList(docList)\n",
    "    #创建存储训练集的索引值的列表\n",
    "    trainingSet =list(range(50)); \n",
    "    #创建存储测试集的索引值的列表\n",
    "    testSet= [] \n",
    "    #从50个邮件中，随机挑选出40个作为训练集，10个作为测试集\n",
    "    for i in range(10):\n",
    "        #随机选取索引值\n",
    "        randIndex = int(np.random.uniform(0, len(trainingSet)))\n",
    "        #添加测试集的索引值\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        #在训练集的列表中删除添加到测试集的索引值\n",
    "        del(list(trainingSet)[randIndex])\n",
    "    #创建训练集矩阵和训练集类别标签向量\n",
    "    trainMat = []; \n",
    "    trainClasses = []\n",
    "    #遍历训练集，目前只有40个训练集\n",
    "    for docIndex in trainingSet:\n",
    "        #将生成的词集模型添加到训练矩阵中\n",
    "        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))\n",
    "        #将类别标签添加到训练集的类别标签向量中\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    \"\"\"\n",
    "    训练朴素贝叶斯模型\n",
    "    \"\"\"\n",
    "    #训练朴素贝叶斯模型\n",
    "    p0V, p1V, pSpam = trainNB(np.array(trainMat), np.array(trainClasses))\n",
    "    #错误分类计数\n",
    "    errorCount = 0\n",
    "    #遍历测试集\n",
    "    for docIndex in testSet:    \n",
    "        #测试集的词集模型\n",
    "        wordVector = setOfWords2Vec(vocabList, docList[docIndex])\n",
    "        if classifyNB(np.array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "            print(\"classification error\", docList[docIndex])\n",
    "    print('the error rate is: ', float(errorCount)/len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification error ['that', 'cold', 'there', 'going', 'retirement', 'party', 'are', 'the', 'leaves', 'changing', 'color']\n",
      "classification error ['arvind', 'thirumalai', 'commented', 'your', 'status', 'arvind', 'wrote', 'you', 'know', 'reply', 'this', 'email', 'comment', 'this', 'status']\n",
      "classification error ['thanks', 'peter', 'definitely', 'check', 'this', 'how', 'your', 'book', 'going', 'heard', 'chapter', 'came', 'and', 'was', 'good', 'shape', 'hope', 'you', 'are', 'doing', 'well', 'cheers', 'troy']\n",
      "classification error ['jay', 'stepp', 'commented', 'your', 'status', 'jay', 'wrote', 'the', 'reply', 'this', 'email', 'comment', 'this', 'status', 'see', 'the', 'comment', 'thread', 'follow', 'the', 'link', 'below']\n",
      "classification error ['benoit', 'mandelbrot', '1924', '2010', 'benoit', 'mandelbrot', '1924', '2010', 'wilmott', 'team', 'benoit', 'mandelbrot', 'the', 'mathematician', 'the', 'father', 'fractal', 'mathematics', 'and', 'advocate', 'more', 'sophisticated', 'modelling', 'quantitative', 'finance', 'died', '14th', 'october', '2010', 'aged', 'wilmott', 'magazine', 'has', 'often', 'featured', 'mandelbrot', 'his', 'ideas', 'and', 'the', 'work', 'others', 'inspired', 'his', 'fundamental', 'insights', 'you', 'must', 'logged', 'view', 'these', 'articles', 'from', 'past', 'issues', 'wilmott', 'magazine']\n",
      "classification error ['will', 'there', 'the', 'latest']\n",
      "classification error ['linkedin', 'kerry', 'haloney', 'requested', 'add', 'you', 'connection', 'linkedin', 'peter', 'like', 'add', 'you', 'professional', 'network', 'linkedin', 'kerry', 'haloney']\n",
      "the error rate is:  0.7\n"
     ]
    }
   ],
   "source": [
    "spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
